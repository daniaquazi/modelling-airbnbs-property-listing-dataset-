{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules, cleaning tabular data, selecting all columns, and extracting features and target variables from a DataFrame\n",
    "import pandas as pd\n",
    "from tabular_data import hello\n",
    "h = hello()\n",
    "df = pd.read_csv(\"/Users/dq/Documents/aicore_project/Airbnb_Project/AirBnbData.csv\")\n",
    "df = h.clean_tabular_data(df)\n",
    "df = df.iloc[:,:]\n",
    "x, y = h.load_airbnb(df,\"Price_Night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      105.0\n",
       "1       92.0\n",
       "2       52.0\n",
       "3      132.0\n",
       "5      143.0\n",
       "       ...  \n",
       "982    240.0\n",
       "983     78.0\n",
       "984    113.0\n",
       "985     80.0\n",
       "987    104.0\n",
       "Name: Price_Night, Length: 830, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.58315067e+09, -4.60381892e+09, -8.37268808e+09, -6.22614852e+09,\n",
       "       -7.97245172e+09, -8.81841493e+09, -8.09490396e+09, -1.87331501e+09,\n",
       "       -8.22214556e+09, -6.82511452e+09, -4.76012809e+09, -5.83421014e+09,\n",
       "       -6.55105581e+09, -6.27655846e+09, -3.38682706e+09, -6.44786585e+09,\n",
       "       -4.35764092e+09, -6.46270299e+09, -5.28050444e+09, -5.29192264e+09,\n",
       "       -8.87646060e+09, -8.08843711e+09,  3.99512079e+08, -1.55106214e+09,\n",
       "       -2.50189581e+09, -5.91243998e+09, -1.43228059e+10, -3.48353944e+09,\n",
       "       -3.87764556e+09, -3.63477298e+09, -1.31604073e+10, -5.41216572e+09,\n",
       "       -4.17705818e+09, -5.37904000e+09, -2.96068658e+09, -2.22779523e+09,\n",
       "       -5.12352504e+08, -4.88210463e+09, -1.92754892e+09, -3.99147616e+09,\n",
       "       -2.11297722e+09, -5.99957863e+09, -2.79338904e+09,  2.57747901e+08,\n",
       "       -4.51782568e+09, -5.86017713e+09, -8.05093452e+09, -7.66804848e+09,\n",
       "       -4.33933943e+09, -4.12952408e+09, -1.25816104e+10, -1.46663827e+09,\n",
       "       -4.77070486e+08, -3.44738696e+09, -3.16818639e+09, -3.60958956e+09,\n",
       "       -4.18853750e+09, -4.57469841e+09, -2.97623003e+09, -4.94109642e+09,\n",
       "       -7.07819063e+09, -3.89405525e+09, -4.31404698e+09, -5.32626771e+09,\n",
       "       -6.03441770e+09, -8.94538499e+09, -7.85403103e+09, -8.13522876e+09,\n",
       "       -4.32279380e+09, -4.35639803e+09, -9.35555279e+09, -8.34674804e+09,\n",
       "       -8.38155187e+09, -5.75358014e+09, -4.71607949e+09, -4.56410416e+09,\n",
       "       -6.16048929e+09, -3.90004718e+09, -2.13988178e+09, -9.50759348e+09,\n",
       "       -7.49654696e+09, -6.90424564e+09, -2.88459313e+09, -2.60750136e+09,\n",
       "       -6.81350801e+09, -1.27643353e+10, -2.13270350e+09, -3.48215671e+09,\n",
       "       -5.17845972e+09, -8.63553346e+09, -3.87574955e+09, -8.75250485e+09,\n",
       "       -4.40429406e+09, -7.40320240e+09, -8.34820289e+09, -5.28104120e+09,\n",
       "       -6.51986025e+09, -3.04248192e+09, -4.76776621e+09, -8.03063155e+09,\n",
       "       -5.32927768e+09, -5.72487162e+09, -3.98056562e+09, -6.14994381e+09,\n",
       "       -8.71594102e+09, -5.21059666e+09, -1.12289538e+10, -6.03278836e+09,\n",
       "       -4.72617056e+09, -5.01890140e+09, -7.80290125e+09, -5.34564482e+09,\n",
       "       -7.00304148e+09, -4.53347149e+09, -6.84584575e+09, -5.11180818e+09,\n",
       "       -4.79291835e+09, -7.76105825e+09, -1.07620560e+10, -5.81372581e+09,\n",
       "       -7.01420432e+09, -3.37039585e+09, -8.09726725e+09, -2.91188711e+09,\n",
       "       -5.44336746e+09, -6.61535934e+09, -5.97887391e+09, -8.33582843e+09,\n",
       "       -3.47072670e+09, -1.90200694e+09, -6.22430217e+09, -6.45305303e+09,\n",
       "       -6.07859425e+09, -5.92708233e+09, -5.15324646e+09, -3.44255520e+09,\n",
       "       -4.39197418e+09, -6.22683884e+09, -4.48240169e+09,  1.04544067e+08,\n",
       "       -5.11592486e+09, -9.81569766e+09, -3.76766704e+09, -8.79865711e+09,\n",
       "       -7.51138079e+09, -9.38872878e+09, -1.73232378e+09, -7.24692665e+09,\n",
       "       -2.58953908e+09, -4.08355672e+09, -1.81193202e+09, -3.99007576e+09,\n",
       "       -6.67644180e+09, -2.92498435e+09, -6.71285185e+09, -5.36724921e+08,\n",
       "       -9.66351385e+09, -6.44082501e+09, -4.14184185e+09, -4.74109329e+09,\n",
       "       -5.97521891e+09, -6.45904172e+09, -6.77365740e+09, -5.50608444e+09,\n",
       "       -7.50945211e+09, -4.04448986e+09, -1.18504635e+10, -8.45338234e+09,\n",
       "       -9.06531143e+09, -6.18741225e+08, -6.55105581e+09, -3.40268173e+09,\n",
       "       -6.77042426e+09, -1.87743169e+09, -8.18664086e+09, -8.80356148e+09,\n",
       "       -5.74245019e+09, -7.16766087e+09, -5.32465702e+09, -4.11259985e+09,\n",
       "       -4.98159118e+09, -6.21504427e+09, -8.80025882e+09, -1.00805395e+10,\n",
       "       -9.39912170e+09, -7.79425745e+09, -7.53757196e+09, -9.40100429e+09,\n",
       "       -7.03803471e+09, -2.57401324e+09, -7.26123599e+09, -2.47554093e+09,\n",
       "       -5.73215246e+09, -7.59562024e+09, -8.32867255e+08, -3.36560952e+09,\n",
       "       -5.49555202e+09, -5.61497864e+09, -6.74202302e+09, -1.05126900e+10,\n",
       "       -1.70472544e+09, -4.30553367e+09, -6.56704609e+09, -7.46614575e+09,\n",
       "        9.02483108e+09, -5.29162145e+09, -2.80750548e+09,  5.23208991e+08])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splits the data into training and testing sets, initializes a SGD regressor, \n",
    "# fits the model to the training data, makes predictions on the test set, and calculates the predicted values for the test set.\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "model = SGDRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>81.0</td>\n",
       "      <td>-5.583151e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>222.0</td>\n",
       "      <td>-4.603819e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>225.0</td>\n",
       "      <td>-8.372688e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>106.0</td>\n",
       "      <td>-6.226149e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>170.0</td>\n",
       "      <td>-7.972452e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>132.0</td>\n",
       "      <td>-7.466146e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>91.0</td>\n",
       "      <td>9.024831e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>211.0</td>\n",
       "      <td>-5.291621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>145.0</td>\n",
       "      <td>-2.807505e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>23.0</td>\n",
       "      <td>5.232090e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual     Predicted\n",
       "761    81.0 -5.583151e+09\n",
       "45    222.0 -4.603819e+09\n",
       "550   225.0 -8.372688e+09\n",
       "11    106.0 -6.226149e+09\n",
       "446   170.0 -7.972452e+09\n",
       "..      ...           ...\n",
       "870   132.0 -7.466146e+09\n",
       "737    91.0  9.024831e+09\n",
       "788   211.0 -5.291621e+09\n",
       "418   145.0 -2.807505e+09\n",
       "239    23.0  5.232090e+08\n",
       "\n",
       "[208 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a pandas DataFrame with two columns: 'Actual' and 'Predicted\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guests</th>\n",
       "      <th>beds</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>Cleanliness_rate</th>\n",
       "      <th>Accuracy_rate</th>\n",
       "      <th>Communication_rate</th>\n",
       "      <th>Location_rate</th>\n",
       "      <th>Check-in_rate</th>\n",
       "      <th>Value_rate</th>\n",
       "      <th>amenities_count</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     guests  beds  bathrooms  Cleanliness_rate  Accuracy_rate  \\\n",
       "761     2.0   1.0        1.0               4.8            5.0   \n",
       "45      6.0   3.0        1.0               4.9            5.0   \n",
       "550     2.0   1.0        1.0               4.6            4.6   \n",
       "11      5.0   4.0        1.0               4.3            4.5   \n",
       "446     4.0   3.0        1.0               4.9            4.9   \n",
       "..      ...   ...        ...               ...            ...   \n",
       "870     6.0   5.0        1.5               5.0            5.0   \n",
       "737     6.0   3.0        2.0               5.0            5.0   \n",
       "788     4.0   2.0        1.0               5.0            5.0   \n",
       "418     2.0   1.0        1.5               5.0            5.0   \n",
       "239     2.0   1.0        1.0               4.8            4.5   \n",
       "\n",
       "     Communication_rate  Location_rate  Check-in_rate  Value_rate  \\\n",
       "761                 5.0            5.0            5.0         4.8   \n",
       "45                  5.0            5.0            5.0         4.8   \n",
       "550                 4.6            5.0            4.6         4.6   \n",
       "11                  4.4            4.8            4.5         4.1   \n",
       "446                 5.0            4.9            5.0         4.9   \n",
       "..                  ...            ...            ...         ...   \n",
       "870                 5.0            5.0            5.0         5.0   \n",
       "737                 5.0            4.3            4.3         5.0   \n",
       "788                 5.0            5.0            5.0         4.9   \n",
       "418                 5.0            4.9            5.0         4.9   \n",
       "239                 4.9            4.5            4.6         4.8   \n",
       "\n",
       "     amenities_count  bedrooms  \n",
       "761             24.0       1.0  \n",
       "45              28.0       2.0  \n",
       "550             38.0       1.0  \n",
       "11              10.0       1.0  \n",
       "446             56.0       2.0  \n",
       "..               ...       ...  \n",
       "870             61.0       3.0  \n",
       "737             14.0       2.0  \n",
       "788             36.0       2.0  \n",
       "418             25.0       1.0  \n",
       "239             23.0       1.0  \n",
       "\n",
       "[208 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting 'guests' on the x-axis and 'Price_Night' on the y-axis\n",
    "import numpy as np\n",
    "plt.scatter(X_test['guests'], y_test, color='blue')\n",
    "plt.scatter(X_test['bedrooms'], y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6235928567.913321"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#measures the average of error squares i.e. the average squared difference between the estimated values and true value.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6355620388.999379"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1267386333541525.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r2 score: regression score function. Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3409520697768573.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'epsilon_insensitive', 'learning_rate': 'optimal'}\n",
      "20428.45394646988\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV: process of performing hyperparameter tuning in order to determine the optimal values for a given model.\n",
    "def custom_tune_regression_model_hyperparameters(model, set, hyperparameters):\n",
    "    best_mse = float('inf')\n",
    "    best_reg = None\n",
    "    for loss in hyperparameters['loss']:\n",
    "        # print('training for alpha = {}'.format(alpha))\n",
    "        for learning_rate in hyperparameters['learning_rate']:\n",
    "            # print('training for eta0 = {}'.format(eta0))\n",
    "            m = model(loss=loss, learning_rate=learning_rate)\n",
    "            m.fit(X_train, y_train)\n",
    "            y_pred = m.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_params = {'loss': loss, 'learning_rate': learning_rate}\n",
    "                best_reg = m\n",
    "    return best_reg, best_params, best_mse\n",
    "\n",
    "set = [X_train, X_test, y_train, y_test]\n",
    "model = SGDRegressor\n",
    "# hyperparameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "#                    'eta0': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "hyperparameters={\"loss\":['squared_error', 'huber', 'epsilon_insensitive','squared_epsilon_insensitive'],\n",
    "                 \"learning_rate\":['constant', 'optimal', 'invscaling', 'adaptive']}\n",
    "best_reg, best_params, best_mse = custom_tune_regression_model_hyperparameters(model, set,hyperparameters)\n",
    "print(best_params)\n",
    "print(best_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "def save_model_to_file(filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "def save_hyperparameters_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(hyperparameters, f)\n",
    "\n",
    "def save_metrics_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(metrics, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def tune_regression_model_hyperparameters(model, hyperparameters):\n",
    "    grid_search = GridSearchCV(model, hyperparameters, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                   'eta0': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "model = SGDRegressor()\n",
    "metrics = tune_regression_model_hyperparameters(model, hyperparameters)\n",
    "\n",
    "save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/model.joblib')\n",
    "save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/hyperparameters.json')\n",
    "save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.01, 'eta0': 0.001}, -8977.707516877283)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "hyperparameters = {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                   'max_depth': [2,4,6,8,10,12]}\n",
    "model = tree.DecisionTreeRegressor()\n",
    "metrics = tune_regression_model_hyperparameters(model, hyperparameters)\n",
    "\n",
    "save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/decisiontree/model.joblib')\n",
    "save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/decisiontree/hyperparamenters.json')\n",
    "save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/decisiontree/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'squared_error', 'max_depth': 2}, -9783.082294632852)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=2'>3</a>\u001b[0m hyperparameters \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m60\u001b[39m, \u001b[39m70\u001b[39m, \u001b[39m80\u001b[39m, \u001b[39m90\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39mNone\u001b[39;00m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=3'>4</a>\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m200\u001b[39m, \u001b[39m400\u001b[39m, \u001b[39m600\u001b[39m, \u001b[39m800\u001b[39m, \u001b[39m1000\u001b[39m]}\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=5'>6</a>\u001b[0m metrics \u001b[39m=\u001b[39m tune_regression_model_hyperparameters(model, hyperparameters)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=7'>8</a>\u001b[0m save_model_to_file(\u001b[39m'\u001b[39m\u001b[39m/Users/dq/Documents/aicore_project/Airbnb_Project/models/randomforest/model.joblib\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000017?line=8'>9</a>\u001b[0m save_hyperparameters_to_file(\u001b[39m'\u001b[39m\u001b[39m/Users/dq/Documents/aicore_project/Airbnb_Project/models/randomforest/hyperparameters.json\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb Cell 13'\u001b[0m in \u001b[0;36mtune_regression_model_hyperparameters\u001b[0;34m(model, hyperparameters)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000012?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtune_regression_model_hyperparameters\u001b[39m(model, hyperparameters):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000012?line=3'>4</a>\u001b[0m     grid_search \u001b[39m=\u001b[39m GridSearchCV(model, hyperparameters, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000012?line=4'>5</a>\u001b[0m     grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dq/Documents/aicore_project/Airbnb_Project/modelling.ipynb#ch0000012?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m grid_search\u001b[39m.\u001b[39mbest_params_, grid_search\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=884'>885</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=885'>886</a>\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=886'>887</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=888'>889</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=890'>891</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=892'>893</a>\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=893'>894</a>\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=894'>895</a>\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1389'>1390</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1390'>1391</a>\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=1391'>1392</a>\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=829'>830</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=830'>831</a>\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=831'>832</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=832'>833</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=833'>834</a>\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=834'>835</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=835'>836</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=837'>838</a>\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=838'>839</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=839'>840</a>\u001b[0m         clone(base_estimator),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=840'>841</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=841'>842</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=842'>843</a>\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=843'>844</a>\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=844'>845</a>\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=845'>846</a>\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=846'>847</a>\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=847'>848</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=848'>849</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=849'>850</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=850'>851</a>\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=851'>852</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=852'>853</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=854'>855</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=855'>856</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=856'>857</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=857'>858</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=858'>859</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py?line=859'>860</a>\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=677'>678</a>\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=678'>679</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=679'>680</a>\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=681'>682</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=682'>683</a>\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py?line=683'>684</a>\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=438'>439</a>\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=439'>440</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=440'>441</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=441'>442</a>\u001b[0m ]\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=443'>444</a>\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=444'>445</a>\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=445'>446</a>\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=446'>447</a>\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=447'>448</a>\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=448'>449</a>\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=449'>450</a>\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=450'>451</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=451'>452</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=452'>453</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=453'>454</a>\u001b[0m )(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=454'>455</a>\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=455'>456</a>\u001b[0m         t,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=456'>457</a>\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=457'>458</a>\u001b[0m         X,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=458'>459</a>\u001b[0m         y,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=459'>460</a>\u001b[0m         sample_weight,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=460'>461</a>\u001b[0m         i,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=461'>462</a>\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=462'>463</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=463'>464</a>\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=464'>465</a>\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=465'>466</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=466'>467</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=467'>468</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=469'>470</a>\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=470'>471</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1042'>1043</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1043'>1044</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1045'>1046</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1046'>1047</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1049'>1050</a>\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1050'>1051</a>\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=1051'>1052</a>\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=858'>859</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=859'>860</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=860'>861</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=861'>862</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=776'>777</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=777'>778</a>\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=778'>779</a>\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=779'>780</a>\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=780'>781</a>\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=781'>782</a>\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=782'>783</a>\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=783'>784</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=205'>206</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=206'>207</a>\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=207'>208</a>\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=208'>209</a>\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=209'>210</a>\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=569'>570</a>\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=570'>571</a>\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py?line=571'>572</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=257'>258</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=258'>259</a>\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=259'>260</a>\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=260'>261</a>\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=261'>262</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py?line=262'>263</a>\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=213'>214</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=214'>215</a>\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py?line=215'>216</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=181'>182</a>\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=182'>183</a>\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=184'>185</a>\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=185'>186</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=186'>187</a>\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1277'>1278</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1278'>1279</a>\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1279'>1280</a>\u001b[0m ):\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1280'>1281</a>\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1281'>1282</a>\u001b[0m \n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1282'>1283</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1311'>1312</a>\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1312'>1313</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1314'>1315</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1315'>1316</a>\u001b[0m         X,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1316'>1317</a>\u001b[0m         y,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1317'>1318</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1318'>1319</a>\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1319'>1320</a>\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1320'>1321</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=1321'>1322</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=408'>409</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=409'>410</a>\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=410'>411</a>\u001b[0m         splitter,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=411'>412</a>\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=416'>417</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=417'>418</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=419'>420</a>\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=421'>422</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py?line=422'>423</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "hyperparameters = {'max_depth': [60, 70, 80, 90, 100, None],\n",
    "                   'n_estimators': [200, 400, 600, 800, 1000]}\n",
    "model = RandomForestRegressor()\n",
    "metrics = tune_regression_model_hyperparameters(model, hyperparameters)\n",
    "\n",
    "save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/randomforest/model.joblib')\n",
    "save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/randomforest/hyperparameters.json')\n",
    "save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/randomforest/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 100, 'n_estimators': 400}, -8846.470856985397)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "hyperparameters = {\"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "                    \"loss\":['squared_error', 'huber', 'quantile','absolute_error']}\n",
    "model = GradientBoostingRegressor()\n",
    "metrics = tune_regression_model_hyperparameters(model, hyperparameters)\n",
    "\n",
    "save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/gradientboostingregressor/model.joblib')\n",
    "save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/gradientboostingregressor/hyperparamenters.json')\n",
    "save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/gradientboostingregressor/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'loss': 'huber', 'n_estimators': 200}, -8994.84460737376)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_models():\n",
    "    path = '/Users/dq/Documents/aicore_project/Airbnb_Project/models/'\n",
    "    hyperparameters = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                   'eta0': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "    SGDRregressor = SGDRegressor()\n",
    "    sgdr_metrics = tune_regression_model_hyperparameters(SGDRregressor, hyperparameters)\n",
    "\n",
    "    save_model_to_file(path + 'regression/model.joblib')\n",
    "    save_hyperparameters_to_file(path +'regression/hyperparameters.json')\n",
    "    save_metrics_to_file(path + 'regression/metrics.json')\n",
    "\n",
    "    hyperparameters = {'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "                   'max_depth': [2,4,6,8,10,12]}\n",
    "    decision_tree = tree.DecisionTreeRegressor()\n",
    "    decisiontree_metrics = tune_regression_model_hyperparameters(decision_tree, hyperparameters)\n",
    "\n",
    "    save_model_to_file(path + 'decisiontree/model.joblib')\n",
    "    save_hyperparameters_to_file(path + 'decisiontree/hyperparamenters.json')\n",
    "    save_metrics_to_file(path + 'decisiontree/metrics.json')\n",
    "\n",
    "    hyperparameters = {'max_depth': [60, 70, 80, 90, 100, None],\n",
    "                   'n_estimators': [200, 400, 600, 800, 1000]}\n",
    "    random_forest = RandomForestRegressor()\n",
    "    random_forest_metrics = tune_regression_model_hyperparameters(random_forest, hyperparameters)\n",
    "\n",
    "    save_model_to_file(path + 'randomforest/model.joblib')\n",
    "    save_hyperparameters_to_file(path + 'randomforest/hyperparameters.json')\n",
    "    save_metrics_to_file(path + 'randomforest/metrics.json')\n",
    "\n",
    "    hyperparameters = {\"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "                    \"loss\":['squared_error', 'huber', 'quantile','absolute_error']}\n",
    "    gradient_booster = GradientBoostingRegressor()\n",
    "    gradient_booster_metrics = tune_regression_model_hyperparameters(gradient_booster, hyperparameters)\n",
    "\n",
    "    save_model_to_file(path + 'gradientboostingregressor/model.joblib')\n",
    "    save_hyperparameters_to_file(path + 'gradientboostingregressor/hyperparamenters.json')\n",
    "    save_metrics_to_file(path + 'gradientboostingregressor/metrics.json')\n",
    "\n",
    "evaluate_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor() ({'alpha': 0.001, 'eta0': 0.001}, -9149.22024024143)\n",
      "DecisionTreeRegressor() ({'criterion': 'squared_error', 'max_depth': 2}, -9783.082294632852)\n",
      "RandomForestRegressor() ({'max_depth': 60, 'n_estimators': 1000}, -8878.579065954904)\n",
      "GradientBoostingRegressor() ({'loss': 'absolute_error', 'n_estimators': 400}, -9000.320703240492)\n"
     ]
    }
   ],
   "source": [
    "def find_best_model():\n",
    "\thyperparameters = [\n",
    "\t{\n",
    "\t\t'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "\t\t'eta0': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "\t\t'max_depth': [2,4,6,8,10,12]\n",
    "\t},\n",
    "\t{\n",
    "\t\t'max_depth': [60, 70, 80, 90, 100],\n",
    "\t\t'n_estimators': [200, 400, 600, 800, 1000]\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "\t\t\"loss\":['squared_error', 'huber', 'quantile','absolute_error']\n",
    "\t}]\n",
    "\tnew_list = []\n",
    "\tmodels = [\n",
    "        SGDRegressor(),\n",
    "        tree.DecisionTreeRegressor(),\n",
    "\t\tRandomForestRegressor(),\n",
    "\t\tGradientBoostingRegressor()]\n",
    "\t\n",
    "\tlist_zip = list(zip(models, hyperparameters))\n",
    "\t\n",
    "\tfor i in range(len(list_zip)):\n",
    "\t\tmodel, hp = list_zip[i]\n",
    "\t\tmetrics = tune_regression_model_hyperparameters(model, hp)\n",
    "\t\tprint(model, metrics)\n",
    "find_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = [\n",
    "{\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'eta0': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "},\n",
    "{\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
    "    'max_depth': [2,4,6,8,10,12]\n",
    "},\n",
    "{\n",
    "    'max_depth': [60, 70, 80, 90, 100, None],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000]\n",
    "},\n",
    "{\n",
    "    \"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "    \"loss\":['squared_error', 'huber', 'quantile','absolute_error']\n",
    "}]\n",
    "models = [\n",
    "    SGDRegressor(),\n",
    "    tree.DecisionTreeRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    GradientBoostingRegressor()]\n",
    "\n",
    "list_zip = list(zip(models, hyperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabular_data import hello\n",
    "h = hello()\n",
    "df = pd.read_csv(\"/Users/dq/Documents/aicore_project/Airbnb_Project/AirBnbData.csv\")\n",
    "df = h.clean_tabular_data(df)\n",
    "df = df.iloc[:,:]\n",
    "x, y = h.load_airbnb(df,\"Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Chalets', 'Treehouses', 'Chalets', 'Treehouses', 'Amazing pools',\n",
       "       'Chalets', 'Treehouses', 'Treehouses', 'Chalets', 'Chalets',\n",
       "       'Chalets', 'Amazing pools', 'Chalets', 'Beachfront', 'Chalets',\n",
       "       'Chalets', 'Amazing pools', 'Chalets', 'Amazing pools',\n",
       "       'Treehouses', 'Amazing pools', 'Amazing pools', 'Treehouses',\n",
       "       'Offbeat', 'Chalets', 'Treehouses', 'Amazing pools', 'Offbeat',\n",
       "       'Treehouses', 'Treehouses', 'Amazing pools', 'Treehouses',\n",
       "       'Treehouses', 'Chalets', 'Offbeat', 'Treehouses', 'Treehouses',\n",
       "       'Chalets', 'Treehouses', 'Beachfront', 'Treehouses', 'Chalets',\n",
       "       'Chalets', 'Chalets', 'Offbeat', 'Chalets', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Treehouses', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Treehouses', 'Treehouses', 'Chalets',\n",
       "       'Treehouses', 'Treehouses', 'Offbeat', 'Chalets', 'Chalets',\n",
       "       'Chalets', 'Offbeat', 'Chalets', 'Treehouses', 'Amazing pools',\n",
       "       'Amazing pools', 'Amazing pools', 'Chalets', 'Chalets',\n",
       "       'Amazing pools', 'Chalets', 'Amazing pools', 'Amazing pools',\n",
       "       'Chalets', 'Offbeat', 'Chalets', 'Treehouses', 'Treehouses',\n",
       "       'Amazing pools', 'Chalets', 'Amazing pools', 'Offbeat',\n",
       "       'Amazing pools', 'Amazing pools', 'Amazing pools', 'Chalets',\n",
       "       'Chalets', 'Offbeat', 'Beachfront', 'Treehouses', 'Amazing pools',\n",
       "       'Treehouses', 'Amazing pools', 'Amazing pools', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Treehouses', 'Treehouses',\n",
       "       'Treehouses', 'Amazing pools', 'Chalets', 'Treehouses',\n",
       "       'Beachfront', 'Amazing pools', 'Amazing pools', 'Amazing pools',\n",
       "       'Offbeat', 'Treehouses', 'Amazing pools', 'Amazing pools',\n",
       "       'Amazing pools', 'Treehouses', 'Chalets', 'Chalets', 'Treehouses',\n",
       "       'Chalets', 'Amazing pools', 'Beachfront', 'Chalets', 'Treehouses',\n",
       "       'Amazing pools', 'Treehouses', 'Beachfront', 'Chalets',\n",
       "       'Amazing pools', 'Beachfront', 'Treehouses', 'Treehouses',\n",
       "       'Chalets', 'Amazing pools', 'Chalets', 'Chalets', 'Chalets',\n",
       "       'Treehouses', 'Treehouses', 'Beachfront', 'Chalets', 'Treehouses',\n",
       "       'Chalets', 'Amazing pools', 'Chalets', 'Treehouses', 'Chalets',\n",
       "       'Treehouses', 'Treehouses', 'Amazing pools', 'Treehouses',\n",
       "       'Treehouses', 'Offbeat', 'Treehouses', 'Chalets', 'Treehouses',\n",
       "       'Amazing pools', 'Offbeat', 'Amazing pools', 'Offbeat', 'Chalets',\n",
       "       'Treehouses', 'Amazing pools', 'Amazing pools', 'Chalets',\n",
       "       'Beachfront', 'Amazing pools', 'Treehouses', 'Amazing pools',\n",
       "       'Beachfront', 'Chalets', 'Treehouses', 'Chalets', 'Amazing pools',\n",
       "       'Chalets', 'Treehouses', 'Amazing pools', 'Chalets', 'Chalets',\n",
       "       'Amazing pools', 'Amazing pools', 'Treehouses', 'Chalets',\n",
       "       'Chalets', 'Amazing pools', 'Amazing pools', 'Amazing pools',\n",
       "       'Chalets', 'Chalets', 'Chalets', 'Amazing pools', 'Offbeat',\n",
       "       'Chalets', 'Treehouses', 'Treehouses', 'Chalets', 'Treehouses',\n",
       "       'Treehouses', 'Treehouses', 'Chalets', 'Chalets', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Treehouses', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Chalets', 'Chalets'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36672527752752043"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test, y_pred, average='macro')\n",
    "f1_score(y_test, y_pred, average='micro')\n",
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30519282985649493"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train, y_train_pred, average='macro')\n",
    "f1_score(y_train, y_train_pred, average='micro')\n",
    "f1_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3979102503356235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test, y_pred, average='macro')\n",
    "precision_score(y_test, y_pred, average='micro')\n",
    "precision_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3179806028204611"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_train, y_train_pred, average='macro')\n",
    "precision_score(y_train, y_train_pred, average='micro')\n",
    "precision_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39903846153846156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test, y_pred, average='macro')\n",
    "recall_score(y_test, y_pred, average='micro')\n",
    "recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3360128617363344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_train, y_train_pred, average='macro')\n",
    "recall_score(y_train, y_train_pred, average='micro')\n",
    "recall_score(y_train, y_train_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39903846153846156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3360128617363344"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_train, y_train_pred)\n",
    "accuracy_score(y_train, y_train_pred)\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "def save_model_to_file(filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "def save_hyperparameters_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(hyperparameters, f)\n",
    "\n",
    "def save_metrics_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "def tune_classification_model_hyperparameters(X_train, y_train):\n",
    "    algos = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(),\n",
    "            'params': {'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "        },\n",
    "        'tree.DecisionTreeClassifier': {\n",
    "            'model': tree.DecisionTreeClassifier(),\n",
    "            'params': {'criterion' : ['gini', 'entropy', 'log_loss'], 'max_depth': [2,4,6,8,10,12]\n",
    "            }\n",
    "        },\n",
    "        'RandomForestClassifier': {\n",
    "            'model': RandomForestClassifier(),\n",
    "            'params': {'criterion' : ['gini', 'entropy', 'log_loss'], 'n_estimators': [200, 400, 600, 800, 1000]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoostingClassifier': {\n",
    "            'model': GradientBoostingClassifier(),\n",
    "            'params': {'n_estimators' : [200, 400, 600, 800, 1000], 'loss': ['log_loss', 'deviance', 'exponential']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    metrics = []\n",
    "    for algo_name, config in algos.items():\n",
    "        grid_search =  GridSearchCV(config['model'], config['params'], cv=5, return_train_score=False)\n",
    "        grid_search.fit(X_train,y_train)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_\n",
    "        })\n",
    "    \n",
    "    return max(scores, key=lambda d: d['best_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def tune_classification_model_hyperparameters(model, hyperparameters):\n",
    "#     grid_search =  GridSearchCV(model, hyperparameters, cv=5, return_train_score=False)\n",
    "#     grid_search.fit(X_train,y_train)\n",
    "#     return grid_search.best_params_, grid_search.best_score_\n",
    "    \n",
    "# hyperparameters = {'penalty': ['l1', 'l2', 'elasticnet', 'none'], \n",
    "#                     'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# metrics = tune_classification_model_hyperparameters(model, hyperparameters)\n",
    "\n",
    "# save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/model.joblib')\n",
    "# save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/hyperparameters.json')\n",
    "# save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/regression/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.35529032        nan 0.32469677 0.37450323\n",
      " 0.32949677 0.35526452 0.33592258 0.32148387        nan        nan\n",
      "        nan        nan        nan 0.37610323 0.32145806        nan\n",
      " 0.33430968 0.32309677]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.30865806 0.32790968 0.34237419 0.32627097 0.31348387 0.30212903\n",
      " 0.29259355 0.3376     0.30544516 0.32141935 0.30207742 0.32305806\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.36814194 0.35845161 0.36330323 0.36166452 0.36162581 0.35846452\n",
      " 0.36649032 0.36810323 0.36483871 0.37291613        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 5 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.35530323\n",
      " 0.34242581 0.35692903 0.36491613 0.35530323        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': 'LogisticRegression',\n",
       " 'best_score': 0.37610322580645167,\n",
       " 'best_params': {'penalty': 'none', 'solver': 'newton-cg'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tune_classification_model_hyperparameters(X_train, y_train)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'LogisticRegression',\n",
       " 'best_score': 0.37610322580645167,\n",
       " 'best_params': {'penalty': 'none', 'solver': 'newton-cg'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37610322580645167"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = list(a.values())\n",
    "m = values[0]\n",
    "s = values[1]\n",
    "h = values[2]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'solver'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_keys = list(h.keys())\n",
    "hyperparameter_values = list(h.values())\n",
    "hyperparameter_name_1 = hyperparameter_keys[0]\n",
    "hyperparameter_name_2 = hyperparameter_keys[1]\n",
    "hyperparameter_value_1 = hyperparameter_values[0]\n",
    "hyperparameter_value_2 = hyperparameter_values[1]\n",
    "hyperparameter_name_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LogisticRegression'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chalets', 'Treehouses', 'Treehouses', 'Treehouses',\n",
       "       'Amazing pools', 'Chalets', 'Treehouses', 'Chalets', 'Chalets',\n",
       "       'Chalets', 'Chalets', 'Chalets', 'Chalets', 'Offbeat', 'Chalets',\n",
       "       'Chalets', 'Chalets', 'Treehouses', 'Treehouses', 'Offbeat',\n",
       "       'Beachfront', 'Chalets', 'Treehouses', 'Offbeat', 'Chalets',\n",
       "       'Treehouses', 'Beachfront', 'Offbeat', 'Treehouses', 'Treehouses',\n",
       "       'Beachfront', 'Chalets', 'Offbeat', 'Treehouses', 'Treehouses',\n",
       "       'Treehouses', 'Treehouses', 'Chalets', 'Treehouses', 'Beachfront',\n",
       "       'Treehouses', 'Amazing pools', 'Chalets', 'Offbeat', 'Offbeat',\n",
       "       'Amazing pools', 'Amazing pools', 'Treehouses', 'Treehouses',\n",
       "       'Chalets', 'Beachfront', 'Treehouses', 'Treehouses', 'Chalets',\n",
       "       'Offbeat', 'Treehouses', 'Chalets', 'Chalets', 'Offbeat',\n",
       "       'Chalets', 'Chalets', 'Offbeat', 'Treehouses', 'Chalets',\n",
       "       'Treehouses', 'Amazing pools', 'Amazing pools', 'Beachfront',\n",
       "       'Chalets', 'Treehouses', 'Amazing pools', 'Amazing pools',\n",
       "       'Beachfront', 'Amazing pools', 'Chalets', 'Offbeat', 'Chalets',\n",
       "       'Chalets', 'Chalets', 'Amazing pools', 'Chalets', 'Amazing pools',\n",
       "       'Treehouses', 'Treehouses', 'Amazing pools', 'Beachfront',\n",
       "       'Offbeat', 'Chalets', 'Beachfront', 'Offbeat', 'Treehouses',\n",
       "       'Amazing pools', 'Offbeat', 'Amazing pools', 'Amazing pools',\n",
       "       'Chalets', 'Chalets', 'Chalets', 'Offbeat', 'Beachfront',\n",
       "       'Chalets', 'Treehouses', 'Chalets', 'Beachfront', 'Beachfront',\n",
       "       'Beachfront', 'Beachfront', 'Amazing pools', 'Amazing pools',\n",
       "       'Treehouses', 'Amazing pools', 'Treehouses', 'Amazing pools',\n",
       "       'Offbeat', 'Offbeat', 'Chalets', 'Treehouses', 'Chalets',\n",
       "       'Beachfront', 'Amazing pools', 'Chalets', 'Treehouses',\n",
       "       'Beachfront', 'Chalets', 'Beachfront', 'Chalets', 'Amazing pools',\n",
       "       'Beachfront', 'Treehouses', 'Treehouses', 'Chalets',\n",
       "       'Amazing pools', 'Chalets', 'Chalets', 'Chalets', 'Offbeat',\n",
       "       'Treehouses', 'Amazing pools', 'Treehouses', 'Treehouses',\n",
       "       'Chalets', 'Beachfront', 'Chalets', 'Treehouses', 'Amazing pools',\n",
       "       'Beachfront', 'Treehouses', 'Offbeat', 'Treehouses', 'Treehouses',\n",
       "       'Treehouses', 'Chalets', 'Chalets', 'Treehouses', 'Offbeat',\n",
       "       'Offbeat', 'Offbeat', 'Amazing pools', 'Chalets', 'Treehouses',\n",
       "       'Amazing pools', 'Amazing pools', 'Chalets', 'Offbeat',\n",
       "       'Amazing pools', 'Chalets', 'Beachfront', 'Beachfront', 'Chalets',\n",
       "       'Treehouses', 'Chalets', 'Treehouses', 'Offbeat', 'Treehouses',\n",
       "       'Amazing pools', 'Chalets', 'Chalets', 'Amazing pools', 'Chalets',\n",
       "       'Chalets', 'Chalets', 'Treehouses', 'Amazing pools',\n",
       "       'Amazing pools', 'Chalets', 'Chalets', 'Chalets', 'Chalets',\n",
       "       'Treehouses', 'Offbeat', 'Chalets', 'Treehouses', 'Beachfront',\n",
       "       'Chalets', 'Chalets', 'Chalets', 'Chalets', 'Chalets', 'Chalets',\n",
       "       'Beachfront', 'Treehouses', 'Treehouses', 'Treehouses',\n",
       "       'Amazing pools', 'Treehouses', 'Chalets', 'Chalets', 'Treehouses'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.ensemble\n",
    "X_train, X_test, y_train, y_test=train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "# if m == \"RandomForestClassifier\":\n",
    "#     model = RandomForestClassifier()\n",
    "# elif m == \"tree.DecisionTreeClassifier\":\n",
    "#     model = tree.DecisionTreeClassifier()\n",
    "# elif m == \"LogisticRegression\":\n",
    "#     model = LogisticRegression()\n",
    "# else:\n",
    "#     model = GradientBoostingClassifier()\n",
    "\n",
    "model = LogisticRegression(penalty= 'none', solver= 'newton-cg')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json\n",
    "def save_model_to_file(filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "def save_hyperparameters_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(h, f)\n",
    "\n",
    "def save_metrics_to_file(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/classification/logisticregression/model.joblib')\n",
    "save_hyperparameters_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/classification/logisticregression/hyperparameters.json')\n",
    "save_metrics_to_file('/Users/dq/Documents/aicore_project/Airbnb_Project/models/classification/logisticregression/metrics.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.35529032        nan 0.32309677 0.37450323\n",
      " 0.32949677 0.35526452 0.33270968 0.32469677        nan        nan\n",
      "        nan        nan        nan 0.37610323 0.32145806        nan\n",
      " 0.33430968 0.32309677]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression() ({'penalty': 'none', 'solver': 'newton-cg'}, 0.37610322580645167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.30865806 0.32790968 0.34237419 0.31178065 0.30701935 0.32628387\n",
      " 0.29259355 0.33437419 0.31188387 0.31176774 0.2892129  0.32143226\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier() ({'criterion': 'gini', 'max_depth': 6}, 0.34237419354838705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.33914839 0.3584129  0.3583871  0.37455484 0.3648129  0.3568\n",
      " 0.36330323 0.36167742 0.37135484 0.36327742        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier() ({'criterion': 'gini', 'n_estimators': 800}, 0.3745548387096774)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 75.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/ensemble/_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 5 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.35689032\n",
      " 0.35049032 0.35531613 0.35850323 0.35530323        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier() ({'loss': 'deviance', 'n_estimators': 800}, 0.35850322580645155)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "def tune_classification_model_hyperparameters(model, hyperparameters, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, hyperparameters, cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_params_, grid_search.best_score_, grid_search.best_estimator_\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(),\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier()]\n",
    "\n",
    "hyperparameters = [\n",
    "{   \n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "},\n",
    "\n",
    "{\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [2,4,6,8,10,12]\n",
    "},\n",
    "{\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'n_estimators': [200, 400, 600, 800, 1000]\n",
    "},\n",
    "{\n",
    "    \"n_estimators\": [200, 400, 600, 800, 1000],\n",
    "    \"loss\":['log_loss', 'deviance', 'exponential']\n",
    "}]\n",
    "\n",
    "list_zip = list(zip(models, hyperparameters))\n",
    "for i in range(len(list_zip)):\n",
    "    f = {}\n",
    "    model, hp = list_zip[i]\n",
    "    metrics = tune_classification_model_hyperparameters(model, hp, X_train, y_train)\n",
    "    print(model, metrics)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e47b1a34c05c1e3b83a62d7885c9d1b5ef8a0522d3be0182d0a008ec409b2b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
